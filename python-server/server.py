"""
Python gRPC STT Server with faster-whisper
Go â†” Python ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì„œë²„
"""

import sys
import os
import time
from concurrent import futures
from datetime import datetime

import grpc
import numpy as np
from faster_whisper import WhisperModel

# generated ëª¨ë“ˆ import ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from generated import conversation_pb2
from generated import conversation_pb2_grpc


# ========================================
# Whisper ëª¨ë¸ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ)
# ========================================
print("ğŸ”„ Loading Whisper model (tiny, CPU, int8)...")
model = WhisperModel(
    "tiny",
    device="cpu",
    compute_type="int8"
)
print("âœ… Whisper model loaded successfully!")


class ConversationServicer(conversation_pb2_grpc.ConversationServiceServicer):
    """STT Conversation Service - faster-whisper (Low Latency)"""

    def StreamChat(self, request_iterator, context):
        """
        ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë° RPC í•¸ë“¤ëŸ¬
        - SessionInit ìˆ˜ì‹ : ì„¸ì…˜ ì‹œì‘, ì˜¤ë””ì˜¤ ì„¤ì • ì €ì¥
        - AudioChunk ìˆ˜ì‹ : ë²„í¼ì— ëˆ„ì  â†’ 0.5ì´ˆ ì´ìƒ ì‹œ STT ìˆ˜í–‰
        - ì¸ì‹ ê²°ê³¼ë¥¼ TranscriptPartial/TranscriptFinalë¡œ ë°˜í™˜
        """
        session_id = None
        audio_config = None
        chunk_count = 0
        total_bytes = 0
        stt_count = 0

        # ì˜¤ë””ì˜¤ ë²„í¼ (PCM bytes ëˆ„ì )
        audio_buffer = bytearray()

        # ========================================
        # STT ì„¤ì • (Latency ìµœì í™”)
        # ========================================
        MIN_AUDIO_SECONDS = 0.5  # 0.5ì´ˆ ì´ìƒ ëˆ„ì  ì‹œ STT (ê¸°ì¡´ 1.0ì´ˆ)

        print(f"\n{'='*60}")
        print(f"ğŸ”— New gRPC stream connected at {datetime.now().strftime('%H:%M:%S')}")
        print(f"{'='*60}")

        try:
            for request in request_iterator:
                session_id = request.session_id
                payload_type = request.WhichOneof('payload')

                # ========================================
                # 1. SessionInit ì²˜ë¦¬
                # ========================================
                if payload_type == 'session_init':
                    init = request.session_init
                    audio_config = {
                        'sample_rate': init.sample_rate,
                        'channels': init.channels,
                        'bits_per_sample': init.bits_per_sample,
                        'language': init.language,
                    }
                    print(f"\nâœ… ì„¸ì…˜ ì‹œì‘: [{session_id[:8]}...]")
                    print(f"   ğŸ“‹ SampleRate: {init.sample_rate}Hz")
                    print(f"   ğŸ“‹ Channels: {init.channels}")
                    print(f"   ğŸ“‹ BitsPerSample: {init.bits_per_sample}")
                    print(f"   ğŸ“‹ Language: {init.language}")

                    # TranscriptPartialë¡œ ì„¸ì…˜ ì‹œì‘ ì•Œë¦¼
                    yield conversation_pb2.ChatResponse(
                        session_id=session_id,
                        transcript_partial=conversation_pb2.TranscriptPartial(
                            text="[LISTENING] Session started",
                            confidence=1.0
                        )
                    )

                # ========================================
                # 2. AudioChunk ì²˜ë¦¬ â†’ STT
                # ========================================
                elif payload_type == 'audio_chunk':
                    audio_bytes = request.audio_chunk
                    chunk_count += 1
                    total_bytes += len(audio_bytes)

                    # ë²„í¼ì— ì˜¤ë””ì˜¤ ëˆ„ì 
                    audio_buffer.extend(audio_bytes)

                    # ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° (bytes â†’ seconds)
                    if audio_config:
                        bytes_per_sample = audio_config['bits_per_sample'] // 8
                        samples_per_second = audio_config['sample_rate'] * audio_config['channels']
                        bytes_per_second = samples_per_second * bytes_per_sample
                        buffer_seconds = len(audio_buffer) / bytes_per_second
                    else:
                        # ê¸°ë³¸ê°’: 16kHz, mono, 16bit
                        bytes_per_second = 16000 * 1 * 2
                        buffer_seconds = len(audio_buffer) / bytes_per_second

                    # ë¡œê·¸ ì¶œë ¥ (ì£¼ê¸°ì ìœ¼ë¡œ)
                    if chunk_count % 20 == 1 or chunk_count <= 3:
                        print(f"ğŸ¤ [{session_id[:8]}] Chunk #{chunk_count}: "
                              f"{len(audio_bytes):,} bytes, "
                              f"Buffer: {len(audio_buffer):,} bytes "
                              f"({buffer_seconds:.2f}s)")

                    # ========================================
                    # ìµœì†Œ ì‹œê°„ ì´ìƒ ëˆ„ì ë˜ë©´ STT ìˆ˜í–‰
                    # ========================================
                    if buffer_seconds >= MIN_AUDIO_SECONDS:
                        stt_count += 1
                        start_time = time.time()
                        print(f"ğŸ”Š [{session_id[:8]}] STT #{stt_count}: {buffer_seconds:.2f}s audio...")

                        try:
                            # PCM Int16 â†’ Float32 [-1.0, 1.0] ë³€í™˜
                            audio_array = np.frombuffer(bytes(audio_buffer), dtype=np.int16)
                            audio_float = audio_array.astype(np.float32) / 32768.0

                            # faster-whisper ìŒì„± ì¸ì‹ (Low Latency ì„¤ì •)
                            language = audio_config.get('language', 'ko') if audio_config else 'ko'

                            segments, info = model.transcribe(
                                audio_float,
                                language=language,
                                beam_size=1,  # Greedy Search (ì†ë„ ìš°ì„ )
                                vad_filter=True,
                                vad_parameters={
                                    "min_silence_duration_ms": 300,  # ì§§ì€ ì¹¨ë¬µ í—ˆìš©
                                    "speech_pad_ms": 100,
                                }
                            )

                            # ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ê²°í•©
                            transcription = ""
                            for segment in segments:
                                transcription += segment.text.strip() + " "
                            transcription = transcription.strip()

                            elapsed = time.time() - start_time

                            if transcription:
                                print(f"ğŸ“ [{session_id[:8]}] STT Result ({elapsed:.2f}s): \"{transcription}\"")

                                # TranscriptFinal ì „ì†¡ (text í•„ë“œë§Œ!)
                                yield conversation_pb2.ChatResponse(
                                    session_id=session_id,
                                    transcript_final=conversation_pb2.TranscriptFinal(
                                        text=transcription
                                    )
                                )
                            else:
                                print(f"ğŸ”‡ [{session_id[:8]}] No speech detected ({elapsed:.2f}s)")

                        except Exception as e:
                            print(f"âš ï¸ [{session_id[:8]}] STT Error: {e}")
                            yield conversation_pb2.ChatResponse(
                                session_id=session_id,
                                error=conversation_pb2.ErrorResponse(
                                    code="STT_ERROR",
                                    message=str(e)
                                )
                            )

                        # ë²„í¼ ì´ˆê¸°í™”
                        audio_buffer.clear()

                    # CPU ê³¼ë¶€í•˜ ë°©ì§€ (ìµœì†Œ íœ´ì‹)
                    time.sleep(0.01)

                # ========================================
                # 3. SessionEnd ì²˜ë¦¬
                # ========================================
                elif payload_type == 'session_end':
                    reason = request.session_end.reason

                    # ë‚¨ì€ ë²„í¼ê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ STT ìˆ˜í–‰
                    if len(audio_buffer) > 0 and audio_config:
                        bytes_per_sample = audio_config['bits_per_sample'] // 8
                        samples_per_second = audio_config['sample_rate'] * audio_config['channels']
                        bytes_per_second = samples_per_second * bytes_per_sample
                        buffer_seconds = len(audio_buffer) / bytes_per_second

                        if buffer_seconds >= 0.3:  # 0.3ì´ˆ ì´ìƒì´ë©´ ì²˜ë¦¬
                            print(f"ğŸ”Š [{session_id[:8]}] Final STT: {buffer_seconds:.2f}s remaining...")

                            try:
                                audio_array = np.frombuffer(bytes(audio_buffer), dtype=np.int16)
                                audio_float = audio_array.astype(np.float32) / 32768.0

                                language = audio_config.get('language', 'ko')
                                segments, info = model.transcribe(
                                    audio_float,
                                    language=language,
                                    beam_size=1,
                                    vad_filter=True,
                                )

                                transcription = ""
                                for segment in segments:
                                    transcription += segment.text.strip() + " "
                                transcription = transcription.strip()

                                if transcription:
                                    print(f"ğŸ“ [{session_id[:8]}] Final: \"{transcription}\"")
                                    yield conversation_pb2.ChatResponse(
                                        session_id=session_id,
                                        transcript_final=conversation_pb2.TranscriptFinal(
                                            text=transcription
                                        )
                                    )
                            except Exception as e:
                                print(f"âš ï¸ Final STT Error: {e}")

                    print(f"\nğŸ›‘ ì„¸ì…˜ ì¢…ë£Œ: [{session_id[:8]}...] - {reason}")
                    break

        except grpc.RpcError as e:
            print(f"âŒ gRPC Error: {e}")
        except Exception as e:
            print(f"âŒ Unexpected Error: {e}")
        finally:
            # ì„¸ì…˜ í†µê³„ ì¶œë ¥
            if session_id:
                print(f"\n{'â”€'*60}")
                print(f"ğŸ“Š Session [{session_id[:8]}...] Summary:")
                print(f"   â€¢ Total Chunks: {chunk_count:,}")
                print(f"   â€¢ Total Bytes: {total_bytes:,} ({total_bytes/1024:.1f} KB)")
                print(f"   â€¢ STT Calls: {stt_count}")
                print(f"{'â”€'*60}\n")


def serve():
    """gRPC ì„œë²„ ì‹œì‘"""
    server = grpc.server(
        futures.ThreadPoolExecutor(max_workers=10),
        options=[
            ('grpc.max_send_message_length', 4 * 1024 * 1024),  # 4MB
            ('grpc.max_receive_message_length', 4 * 1024 * 1024),  # 4MB
        ]
    )

    conversation_pb2_grpc.add_ConversationServiceServicer_to_server(
        ConversationServicer(), server
    )

    server.add_insecure_port('0.0.0.0:50051')
    server.start()

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       ğŸ Python STT gRPC Server (faster-whisper)             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Address:  0.0.0.0:50051                                     â•‘
â•‘  Service:  ConversationService.StreamChat                    â•‘
â•‘  Model:    whisper-tiny (CPU, int8)                          â•‘
â•‘  Mode:     STT Low-Latency (0.5s buffer, beam=1)             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    print("â³ Waiting for connections...\n")

    try:
        server.wait_for_termination()
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Server shutting down...")
        server.stop(grace=5)
        print("âœ… Server stopped gracefully.")


if __name__ == '__main__':
    serve()
