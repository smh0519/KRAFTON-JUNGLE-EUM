# gRPC
grpcio>=1.60.0
grpcio-tools>=1.60.0
protobuf>=4.25.0

# AI Models (Qwen3-8B Translation)
torch>=2.1.0
transformers>=4.45.0
accelerate>=0.25.0
bitsandbytes>=0.41.0

# STT - faster-whisper (CTranslate2 optimized)
faster-whisper>=1.0.0

# AWS Services (Translation, TTS)
boto3>=1.34.0
# amazon-transcribe>=0.6.0  # Replaced by faster-whisper

# Optional: vLLM for efficient GPU inference (uncomment for GPU server)
# vllm>=0.2.7

# Utilities
numpy>=1.24.0
webrtcvad>=2.0.10

# Legacy (can be removed)
# edge-tts>=6.1.0
